{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Boyer-Moore Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def z_array(s):\n",
    "    \"\"\" Use Z algorithm (Gusfield theorem 1.4.1) to preprocess s \"\"\"\n",
    "    assert len(s) > 1\n",
    "    z = [len(s)] + [0] * (len(s)-1)\n",
    "    # Initial comparison of s[1:] with prefix\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i] == s[i-1]:\n",
    "            z[1] += 1\n",
    "        else:\n",
    "            break\n",
    "    r, l = 0, 0\n",
    "    if z[1] > 0:\n",
    "        r, l = z[1], 1\n",
    "    for k in range(2, len(s)):\n",
    "        assert z[k] == 0\n",
    "        if k > r:\n",
    "            # Case 1\n",
    "            for i in range(k, len(s)):\n",
    "                if s[i] == s[i-k]:\n",
    "                    z[k] += 1\n",
    "                else:\n",
    "                    break\n",
    "            r, l = k + z[k] - 1, k\n",
    "        else:\n",
    "            # Case 2\n",
    "            # Calculate length of beta\n",
    "            nbeta = r - k + 1\n",
    "            zkp = z[k - l]\n",
    "            if nbeta > zkp:\n",
    "                # Case 2a: Zkp wins\n",
    "                z[k] = zkp\n",
    "            else:\n",
    "                # Case 2b: Compare characters just past r\n",
    "                nmatch = 0\n",
    "                for i in range(r+1, len(s)):\n",
    "                    if s[i] == s[i - k]:\n",
    "                        nmatch += 1\n",
    "                    else:\n",
    "                        break\n",
    "                l, r = k, r + nmatch\n",
    "                z[k] = r - k + 1\n",
    "    return z\n",
    "\n",
    "def n_array(s):\n",
    "    \"\"\" Compile the N array (Gusfield theorem 2.2.2) from the Z array \"\"\"\n",
    "    return z_array(s[::-1])[::-1]\n",
    "\n",
    "\n",
    "def big_l_prime_array(p, n):\n",
    "    \"\"\" Compile L' array (Gusfield theorem 2.2.2) using p and N array.\n",
    "        L'[i] = largest index j less than n such that N[j] = |P[i:]| \"\"\"\n",
    "    lp = [0] * len(p)\n",
    "    for j in range(len(p)-1):\n",
    "        i = len(p) - n[j]\n",
    "        if i < len(p):\n",
    "            lp[i] = j + 1\n",
    "    return lp\n",
    "\n",
    "\n",
    "def big_l_array(p, lp):\n",
    "    \"\"\" Compile L array (Gusfield theorem 2.2.2) using p and L' array.\n",
    "        L[i] = largest index j less than n such that N[j] >= |P[i:]| \"\"\"\n",
    "    l = [0] * len(p)\n",
    "    l[1] = lp[1]\n",
    "    for i in range(2, len(p)):\n",
    "        l[i] = max(l[i-1], lp[i])\n",
    "    return l\n",
    "\n",
    "\n",
    "def small_l_prime_array(n):\n",
    "    \"\"\" Compile lp' array (Gusfield theorem 2.2.4) using N array. \"\"\"\n",
    "    small_lp = [0] * len(n)\n",
    "    for i in range(len(n)):\n",
    "        if n[i] == i+1:  # prefix matching a suffix\n",
    "            small_lp[len(n)-i-1] = i+1\n",
    "    for i in range(len(n)-2, -1, -1):  # \"smear\" them out to the left\n",
    "        if small_lp[i] == 0:\n",
    "            small_lp[i] = small_lp[i+1]\n",
    "    return small_lp\n",
    "\n",
    "def good_suffix_table(p):\n",
    "    \"\"\" Return tables needed to apply good suffix rule. \"\"\"\n",
    "    n = n_array(p)\n",
    "    lp = big_l_prime_array(p, n)\n",
    "    return lp, big_l_array(p, lp), small_l_prime_array(n)\n",
    "\n",
    "\n",
    "def good_suffix_mismatch(i, big_l_prime, small_l_prime):\n",
    "    \"\"\" Given a mismatch at offset i, and given L/L' and l' arrays,\n",
    "        return amount to shift as determined by good suffix rule. \"\"\"\n",
    "    length = len(big_l_prime)\n",
    "    assert i < length\n",
    "    if i == length - 1:\n",
    "        return 0\n",
    "    i += 1  # i points to leftmost matching position of P\n",
    "    if big_l_prime[i] > 0:\n",
    "        return length - big_l_prime[i]\n",
    "    return length - small_l_prime[i]\n",
    "\n",
    "\n",
    "def good_suffix_match(small_l_prime):\n",
    "    \"\"\" Given a full match of P to T, return amount to shift as\n",
    "        determined by good suffix rule. \"\"\"\n",
    "    return len(small_l_prime) - small_l_prime[1]\n",
    "\n",
    "\n",
    "def dense_bad_char_tab(p, amap):\n",
    "    \"\"\" Given pattern string and list with ordered alphabet characters, create\n",
    "        and return a dense bad character table.  Table is indexed by offset\n",
    "        then by character. \"\"\"\n",
    "    tab = []\n",
    "    nxt = [0] * len(amap)\n",
    "    for i in range(0, len(p)):\n",
    "        c = p[i]\n",
    "        assert c in amap\n",
    "        tab.append(nxt[:])\n",
    "        nxt[amap[c]] = i+1\n",
    "    return tab\n",
    "\n",
    "\n",
    "class BoyerMoore(object):\n",
    "    \"\"\" Encapsulates pattern and associated Boyer-Moore preprocessing. \"\"\"\n",
    "    \n",
    "    def __init__(self, p, alphabet='ACGT'):\n",
    "        self.p = p\n",
    "        self.alphabet = alphabet\n",
    "        # Create map from alphabet characters to integers\n",
    "        self.amap = {}\n",
    "        for i in range(len(self.alphabet)):\n",
    "            self.amap[self.alphabet[i]] = i\n",
    "        # Make bad character rule table\n",
    "        self.bad_char = dense_bad_char_tab(p, self.amap)\n",
    "        # Create good suffix rule table\n",
    "        _, self.big_l, self.small_l_prime = good_suffix_table(p)\n",
    "    \n",
    "    def bad_character_rule(self, i, c):\n",
    "        \"\"\" Return # skips given by bad character rule at offset i \"\"\"\n",
    "        assert c in self.amap\n",
    "        ci = self.amap[c]\n",
    "        assert i > (self.bad_char[i][ci]-1)\n",
    "        return i - (self.bad_char[i][ci]-1)\n",
    "    \n",
    "    def good_suffix_rule(self, i):\n",
    "        \"\"\" Given a mismatch at offset i, return amount to shift\n",
    "            as determined by (weak) good suffix rule. \"\"\"\n",
    "        length = len(self.big_l)\n",
    "        assert i < length\n",
    "        if i == length - 1:\n",
    "            return 0\n",
    "        i += 1  # i points to leftmost matching position of P\n",
    "        if self.big_l[i] > 0:\n",
    "            return length - self.big_l[i]\n",
    "        return length - self.small_l_prime[i]\n",
    "    \n",
    "    def match_skip(self):\n",
    "        \"\"\" Return amount to shift in case where P matches T \"\"\"\n",
    "        return len(self.small_l_prime) - self.small_l_prime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCTAGCTCTACGAGTCTA\n",
    "p = 'TCAA'\n",
    "p_bm = BoyerMoore(p, alphabet='ACGT')\n",
    "p_bm.bad_character_rule(2, 'T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCTAGCTCTACGAGTCTA\n",
    "# ACTA\n",
    "p = 'ACTA'\n",
    "p_bm = BoyerMoore(p, alphabet='ACGT')\n",
    "p_bm.good_suffix_rule(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACACGCTCTACGAGTCTA\n",
    "# ACAC\n",
    "p = 'ACAC'\n",
    "p_bm = BoyerMoore(p, alphabet='ACGT')\n",
    "p_bm.match_skip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boyer_moore(p, p_bm, t):   #p_bm = preprocessing\n",
    "    i = 0\n",
    "    occurances = []\n",
    "    while i < len(t) - len(p) + 1 :\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):  #from last to zero scan\n",
    "            if not p[j] == t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurances.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'GCTAGCTCTACGAGTCTA'\n",
    "p = 'TCTA'\n",
    "p_bm = BoyerMoore(p, alphabet='ACGT')   # p_bm = p er preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 14]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boyer_moore(p, p_bm, t)   #occurances print korbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a k-mer index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "class Index(object):\n",
    "    def __init__(self, t, k):\n",
    "        self.k = k                                      # k-mer length = k\n",
    "        self.index = []   \n",
    "        for i in range(len(t) - k + 1):\n",
    "            self.index.append((t[i:i+k], i))            # kmer gula bosano hoise (string, index) touple diye\n",
    "        self.index.sort()\n",
    "        \n",
    "    def query(self, p):\n",
    "        kmer = p[:self.k]                                # given str p theke k ta char nite hbe kmer hisabe\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))   # i = kmer kon index e boste parbe seta find korbe (syxtax e amon), right the left e khujbe and leftmost index return krbe\n",
    "        hits = []\n",
    "        while i < len(self.index):\n",
    "            if self.index[i][0] != kmer:                 # i pawar por i jodi kmer na hoy break \n",
    "                break\n",
    "            hits.append(self.index[i][1])                # i jodi kmer hoy tahole sei kmer er index collect kora hbe\n",
    "            i += 1                                       # i leftmost index return krbe, tai i++ kore dekhte hbe aro hit ache kina\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryIndex(p, t, index):\n",
    "    k = index.k                       # index = Index class er obj. so k = joto k set kora hoise\n",
    "    offsets = []                      # kothay kothay full p str match korse\n",
    "    for i in index.query(p):          # jekhane jekhane k-mer pabe oikhan theke purata scan kore nibe\n",
    "        if p[k:] == t[i+k:i+len(p)]:  # p[k:] karon first k ta k-mer diyei hoye gese. tai k theke len(p) porjonto check krte hbe\n",
    "            offsets.append(i) \n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'ACTTGGAGATCTTTGAGGCTAGGTATTCGGGATCGAAGCTCATTTCGGGGATCGATTACGATATGGTGGGTATTCGGGA'\n",
    "p = 'GGTATTCGGGA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 68]\n"
     ]
    }
   ],
   "source": [
    "index = Index(t, 4)              # t str diye 4-mer set hbe\n",
    "print(queryIndex(p, t, index))   # query diye only k-mer search kore, queryIndex diye full p search kore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Match Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def z_array(s):\n",
    "    \"\"\" Use Z algorithm (Gusfield theorem 1.4.1) to preprocess s \"\"\"\n",
    "    assert len(s) > 1\n",
    "    z = [len(s)] + [0] * (len(s)-1)\n",
    "    # Initial comparison of s[1:] with prefix\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i] == s[i-1]:\n",
    "            z[1] += 1\n",
    "        else:\n",
    "            break\n",
    "    r, l = 0, 0\n",
    "    if z[1] > 0:\n",
    "        r, l = z[1], 1\n",
    "    for k in range(2, len(s)):\n",
    "        assert z[k] == 0\n",
    "        if k > r:\n",
    "            # Case 1\n",
    "            for i in range(k, len(s)):\n",
    "                if s[i] == s[i-k]:\n",
    "                    z[k] += 1\n",
    "                else:\n",
    "                    break\n",
    "            r, l = k + z[k] - 1, k\n",
    "        else:\n",
    "            # Case 2\n",
    "            # Calculate length of beta\n",
    "            nbeta = r - k + 1\n",
    "            zkp = z[k - l]\n",
    "            if nbeta > zkp:\n",
    "                # Case 2a: Zkp wins\n",
    "                z[k] = zkp\n",
    "            else:\n",
    "                # Case 2b: Compare characters just past r\n",
    "                nmatch = 0\n",
    "                for i in range(r+1, len(s)):\n",
    "                    if s[i] == s[i - k]:\n",
    "                        nmatch += 1\n",
    "                    else:\n",
    "                        break\n",
    "                l, r = k, r + nmatch\n",
    "                z[k] = r - k + 1\n",
    "    return z\n",
    "\n",
    "def n_array(s):\n",
    "    \"\"\" Compile the N array (Gusfield theorem 2.2.2) from the Z array \"\"\"\n",
    "    return z_array(s[::-1])[::-1]\n",
    "\n",
    "\n",
    "def big_l_prime_array(p, n):\n",
    "    \"\"\" Compile L' array (Gusfield theorem 2.2.2) using p and N array.\n",
    "        L'[i] = largest index j less than n such that N[j] = |P[i:]| \"\"\"\n",
    "    lp = [0] * len(p)\n",
    "    for j in range(len(p)-1):\n",
    "        i = len(p) - n[j]\n",
    "        if i < len(p):\n",
    "            lp[i] = j + 1\n",
    "    return lp\n",
    "\n",
    "\n",
    "def big_l_array(p, lp):\n",
    "    \"\"\" Compile L array (Gusfield theorem 2.2.2) using p and L' array.\n",
    "        L[i] = largest index j less than n such that N[j] >= |P[i:]| \"\"\"\n",
    "    l = [0] * len(p)\n",
    "    l[1] = lp[1]\n",
    "    for i in range(2, len(p)):\n",
    "        l[i] = max(l[i-1], lp[i])\n",
    "    return l\n",
    "\n",
    "\n",
    "def small_l_prime_array(n):\n",
    "    \"\"\" Compile lp' array (Gusfield theorem 2.2.4) using N array. \"\"\"\n",
    "    small_lp = [0] * len(n)\n",
    "    for i in range(len(n)):\n",
    "        if n[i] == i+1:  # prefix matching a suffix\n",
    "            small_lp[len(n)-i-1] = i+1\n",
    "    for i in range(len(n)-2, -1, -1):  # \"smear\" them out to the left\n",
    "        if small_lp[i] == 0:\n",
    "            small_lp[i] = small_lp[i+1]\n",
    "    return small_lp\n",
    "\n",
    "def good_suffix_table(p):\n",
    "    \"\"\" Return tables needed to apply good suffix rule. \"\"\"\n",
    "    n = n_array(p)\n",
    "    lp = big_l_prime_array(p, n)\n",
    "    return lp, big_l_array(p, lp), small_l_prime_array(n)\n",
    "\n",
    "\n",
    "def good_suffix_mismatch(i, big_l_prime, small_l_prime):\n",
    "    \"\"\" Given a mismatch at offset i, and given L/L' and l' arrays,\n",
    "        return amount to shift as determined by good suffix rule. \"\"\"\n",
    "    length = len(big_l_prime)\n",
    "    assert i < length\n",
    "    if i == length - 1:\n",
    "        return 0\n",
    "    i += 1  # i points to leftmost matching position of P\n",
    "    if big_l_prime[i] > 0:\n",
    "        return length - big_l_prime[i]\n",
    "    return length - small_l_prime[i]\n",
    "\n",
    "\n",
    "def good_suffix_match(small_l_prime):\n",
    "    \"\"\" Given a full match of P to T, return amount to shift as\n",
    "        determined by good suffix rule. \"\"\"\n",
    "    return len(small_l_prime) - small_l_prime[1]\n",
    "\n",
    "\n",
    "def dense_bad_char_tab(p, amap):\n",
    "    \"\"\" Given pattern string and list with ordered alphabet characters, create\n",
    "        and return a dense bad character table.  Table is indexed by offset\n",
    "        then by character. \"\"\"\n",
    "    tab = []\n",
    "    nxt = [0] * len(amap)\n",
    "    for i in range(0, len(p)):\n",
    "        c = p[i]\n",
    "        assert c in amap\n",
    "        tab.append(nxt[:])\n",
    "        nxt[amap[c]] = i+1\n",
    "    return tab\n",
    "\n",
    "\n",
    "class BoyerMoore(object):\n",
    "    \"\"\" Encapsulates pattern and associated Boyer-Moore preprocessing. \"\"\"\n",
    "    \n",
    "    def __init__(self, p, alphabet='ACGT'):\n",
    "        self.p = p\n",
    "        self.alphabet = alphabet\n",
    "        # Create map from alphabet characters to integers\n",
    "        self.amap = {}\n",
    "        for i in range(len(self.alphabet)):\n",
    "            self.amap[self.alphabet[i]] = i\n",
    "        # Make bad character rule table\n",
    "        self.bad_char = dense_bad_char_tab(p, self.amap)\n",
    "        # Create good suffix rule table\n",
    "        _, self.big_l, self.small_l_prime = good_suffix_table(p)\n",
    "    \n",
    "    def bad_character_rule(self, i, c):\n",
    "        \"\"\" Return # skips given by bad character rule at offset i \"\"\"\n",
    "        assert c in self.amap\n",
    "        ci = self.amap[c]\n",
    "        assert i > (self.bad_char[i][ci]-1)\n",
    "        return i - (self.bad_char[i][ci]-1)\n",
    "    \n",
    "    def good_suffix_rule(self, i):\n",
    "        \"\"\" Given a mismatch at offset i, return amount to shift\n",
    "            as determined by (weak) good suffix rule. \"\"\"\n",
    "        length = len(self.big_l)\n",
    "        assert i < length\n",
    "        if i == length - 1:\n",
    "            return 0\n",
    "        i += 1  # i points to leftmost matching position of P\n",
    "        if self.big_l[i] > 0:\n",
    "            return length - self.big_l[i]\n",
    "        return length - self.small_l_prime[i]\n",
    "    \n",
    "    def match_skip(self):\n",
    "        \"\"\" Return amount to shift in case where P matches T \"\"\"\n",
    "        return len(self.small_l_prime) - self.small_l_prime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boyer_moore(p, p_bm, t):   #p_bm = preprocessing\n",
    "    i = 0\n",
    "    occurances = []\n",
    "    while i < len(t) - len(p) + 1 :\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):  #from last to zero scan\n",
    "            if not p[j] == t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurances.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_match(p, t, n):                           # n = max num of mismatches\n",
    "    \n",
    "    all_matches = set()\n",
    "    segment_length = round(len(p)/(n+1))                  # n ta mismatch allowed. tai (n+1) ta tukra korte hbe p ke.\n",
    "    for i in range(n+1):\n",
    "        start = i*segment_length                          # (jototomo tukra * tukrar length) theke start. like 0*3=0 or 1*3=3       \n",
    "        end = min((i+1)*segment_length, len(p))           # (i+1)*segment_len hobe end point\n",
    "        p_bm = BoyerMoore(p[start:end], alphabet='ACGT')  # preprocess korte pathate hbe\n",
    "        matches = boyer_moore(p[start:end], p_bm, t)      # koyta match holo tader offset index dibe\n",
    "        \n",
    "        for m in matches:                                 # proti ta match e jabo (segment match index)\n",
    "            if m < start or m-start+len(p) > len(t):      # seg jekhane start hoise, tar age toh match howa possible na, ar match koranor somoy len(t) exceed kora jabena\n",
    "                continue\n",
    "                \n",
    "            mismatches = 0\n",
    "            for j in range(0, start):                     # segment ta p er jekhan theke start hoise tar ag porjonto p==t hoise kina check\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            \n",
    "            for j in range(end, len(p)):                  # segment jekhane ses hoise tar por theke p er ses porjonto p==t kina check\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            \n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m-start)                  # expected result set e add kore fela\n",
    "    return list(all_matches)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5]\n"
     ]
    }
   ],
   "source": [
    "p = 'AACTTG'\n",
    "t = 'CACTTAATTTG'\n",
    "print(approximate_match(p, t, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AATTTG\n"
     ]
    }
   ],
   "source": [
    "print(t[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "print(approximate_match(p, t, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5]\n"
     ]
    }
   ],
   "source": [
    "print(approximate_match(p, t, 2)) # 2 er besi dile error khacche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(approximate_match(p, t, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1.GRCh38.excerpt.fasta\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = 'http://d28rh4a8wq0iu5.cloudfront.net/ads1/data/chr1.GRCh38.excerpt.fasta'\n",
    "filename = 'chr1.GRCh38.excerpt.fasta'\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TTGAATGCTGAAATCAGCAGGTAATATATGATAATAGAGAAAGCTATCCCGAAGGTGCATAGGTCAACAATACTTGAGCCTAACTCAGTAGATCCTAAAA'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def readGenome(filename):\n",
    "    genome = ''\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line[0] == '>':\n",
    "                genome += line.rstrip()\n",
    "    return genome\n",
    "genome = readGenome('chr1.GRCh38.excerpt.fasta')\n",
    "genome[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(p, t):\n",
    "    scan = 0\n",
    "    occurances = []\n",
    "    for i in range(len(t)-len(p)+1):\n",
    "        scan += 1\n",
    "        match = True\n",
    "        for j in range(len(p)):\n",
    "            if t[i+j] != p[j]:\n",
    "                match = False\n",
    "                break\n",
    "        if match == True:\n",
    "            occurances.append(i)\n",
    "    return scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799954\n"
     ]
    }
   ],
   "source": [
    "scan = naive('GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG', genome)\n",
    "print(scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def z_array(s):\n",
    "    \"\"\" Use Z algorithm (Gusfield theorem 1.4.1) to preprocess s \"\"\"\n",
    "    assert len(s) > 1\n",
    "    z = [len(s)] + [0] * (len(s)-1)\n",
    "    # Initial comparison of s[1:] with prefix\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i] == s[i-1]:\n",
    "            z[1] += 1\n",
    "        else:\n",
    "            break\n",
    "    r, l = 0, 0\n",
    "    if z[1] > 0:\n",
    "        r, l = z[1], 1\n",
    "    for k in range(2, len(s)):\n",
    "        assert z[k] == 0\n",
    "        if k > r:\n",
    "            # Case 1\n",
    "            for i in range(k, len(s)):\n",
    "                if s[i] == s[i-k]:\n",
    "                    z[k] += 1\n",
    "                else:\n",
    "                    break\n",
    "            r, l = k + z[k] - 1, k\n",
    "        else:\n",
    "            # Case 2\n",
    "            # Calculate length of beta\n",
    "            nbeta = r - k + 1\n",
    "            zkp = z[k - l]\n",
    "            if nbeta > zkp:\n",
    "                # Case 2a: Zkp wins\n",
    "                z[k] = zkp\n",
    "            else:\n",
    "                # Case 2b: Compare characters just past r\n",
    "                nmatch = 0\n",
    "                for i in range(r+1, len(s)):\n",
    "                    if s[i] == s[i - k]:\n",
    "                        nmatch += 1\n",
    "                    else:\n",
    "                        break\n",
    "                l, r = k, r + nmatch\n",
    "                z[k] = r - k + 1\n",
    "    return z\n",
    "\n",
    "def n_array(s):\n",
    "    \"\"\" Compile the N array (Gusfield theorem 2.2.2) from the Z array \"\"\"\n",
    "    return z_array(s[::-1])[::-1]\n",
    "\n",
    "\n",
    "def big_l_prime_array(p, n):\n",
    "    \"\"\" Compile L' array (Gusfield theorem 2.2.2) using p and N array.\n",
    "        L'[i] = largest index j less than n such that N[j] = |P[i:]| \"\"\"\n",
    "    lp = [0] * len(p)\n",
    "    for j in range(len(p)-1):\n",
    "        i = len(p) - n[j]\n",
    "        if i < len(p):\n",
    "            lp[i] = j + 1\n",
    "    return lp\n",
    "\n",
    "\n",
    "def big_l_array(p, lp):\n",
    "    \"\"\" Compile L array (Gusfield theorem 2.2.2) using p and L' array.\n",
    "        L[i] = largest index j less than n such that N[j] >= |P[i:]| \"\"\"\n",
    "    l = [0] * len(p)\n",
    "    l[1] = lp[1]\n",
    "    for i in range(2, len(p)):\n",
    "        l[i] = max(l[i-1], lp[i])\n",
    "    return l\n",
    "\n",
    "\n",
    "def small_l_prime_array(n):\n",
    "    \"\"\" Compile lp' array (Gusfield theorem 2.2.4) using N array. \"\"\"\n",
    "    small_lp = [0] * len(n)\n",
    "    for i in range(len(n)):\n",
    "        if n[i] == i+1:  # prefix matching a suffix\n",
    "            small_lp[len(n)-i-1] = i+1\n",
    "    for i in range(len(n)-2, -1, -1):  # \"smear\" them out to the left\n",
    "        if small_lp[i] == 0:\n",
    "            small_lp[i] = small_lp[i+1]\n",
    "    return small_lp\n",
    "\n",
    "def good_suffix_table(p):\n",
    "    \"\"\" Return tables needed to apply good suffix rule. \"\"\"\n",
    "    n = n_array(p)\n",
    "    lp = big_l_prime_array(p, n)\n",
    "    return lp, big_l_array(p, lp), small_l_prime_array(n)\n",
    "\n",
    "\n",
    "def good_suffix_mismatch(i, big_l_prime, small_l_prime):\n",
    "    \"\"\" Given a mismatch at offset i, and given L/L' and l' arrays,\n",
    "        return amount to shift as determined by good suffix rule. \"\"\"\n",
    "    length = len(big_l_prime)\n",
    "    assert i < length\n",
    "    if i == length - 1:\n",
    "        return 0\n",
    "    i += 1  # i points to leftmost matching position of P\n",
    "    if big_l_prime[i] > 0:\n",
    "        return length - big_l_prime[i]\n",
    "    return length - small_l_prime[i]\n",
    "\n",
    "\n",
    "def good_suffix_match(small_l_prime):\n",
    "    \"\"\" Given a full match of P to T, return amount to shift as\n",
    "        determined by good suffix rule. \"\"\"\n",
    "    return len(small_l_prime) - small_l_prime[1]\n",
    "\n",
    "\n",
    "def dense_bad_char_tab(p, amap):\n",
    "    \"\"\" Given pattern string and list with ordered alphabet characters, create\n",
    "        and return a dense bad character table.  Table is indexed by offset\n",
    "        then by character. \"\"\"\n",
    "    tab = []\n",
    "    nxt = [0] * len(amap)\n",
    "    for i in range(0, len(p)):\n",
    "        c = p[i]\n",
    "        assert c in amap\n",
    "        tab.append(nxt[:])\n",
    "        nxt[amap[c]] = i+1\n",
    "    return tab\n",
    "\n",
    "\n",
    "class BoyerMoore(object):\n",
    "    \"\"\" Encapsulates pattern and associated Boyer-Moore preprocessing. \"\"\"\n",
    "    \n",
    "    def __init__(self, p, alphabet='ACGT'):\n",
    "        self.p = p\n",
    "        self.alphabet = alphabet\n",
    "        # Create map from alphabet characters to integers\n",
    "        self.amap = {}\n",
    "        for i in range(len(self.alphabet)):\n",
    "            self.amap[self.alphabet[i]] = i\n",
    "        # Make bad character rule table\n",
    "        self.bad_char = dense_bad_char_tab(p, self.amap)\n",
    "        # Create good suffix rule table\n",
    "        _, self.big_l, self.small_l_prime = good_suffix_table(p)\n",
    "    \n",
    "    def bad_character_rule(self, i, c):\n",
    "        \"\"\" Return # skips given by bad character rule at offset i \"\"\"\n",
    "        assert c in self.amap\n",
    "        ci = self.amap[c]\n",
    "        assert i > (self.bad_char[i][ci]-1)\n",
    "        return i - (self.bad_char[i][ci]-1)\n",
    "    \n",
    "    def good_suffix_rule(self, i):\n",
    "        \"\"\" Given a mismatch at offset i, return amount to shift\n",
    "            as determined by (weak) good suffix rule. \"\"\"\n",
    "        length = len(self.big_l)\n",
    "        assert i < length\n",
    "        if i == length - 1:\n",
    "            return 0\n",
    "        i += 1  # i points to leftmost matching position of P\n",
    "        if self.big_l[i] > 0:\n",
    "            return length - self.big_l[i]\n",
    "        return length - self.small_l_prime[i]\n",
    "    \n",
    "    def match_skip(self):\n",
    "        \"\"\" Return amount to shift in case where P matches T \"\"\"\n",
    "        return len(self.small_l_prime) - self.small_l_prime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boyer_moore(p, p_bm, t):   #p_bm = preprocessing\n",
    "    i = 0\n",
    "    occurances = []\n",
    "    scan = 0\n",
    "    while i < len(t) - len(p) + 1 :\n",
    "        scan += 1\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):  #from last to zero scan\n",
    "            if not p[j] == t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurances.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127974\n"
     ]
    }
   ],
   "source": [
    "t = genome\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "p_bm = BoyerMoore(p, alphabet='ACGT')\n",
    "print(boyer_moore(p, p_bm, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boyer_moore(p, p_bm, t):   #p_bm = preprocessing\n",
    "    i = 0\n",
    "    occurances = []\n",
    "    while i < len(t) - len(p) + 1 :\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):  #from last to zero scan\n",
    "            if not p[j] == t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurances.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_match(p, t, n):                           # n = max num of mismatches\n",
    "    \n",
    "    all_matches = set()\n",
    "    segment_length = round(len(p)/(n+1))                  # n ta mismatch allowed. tai (n+1) ta tukra korte hbe p ke.\n",
    "    for i in range(n+1):\n",
    "        start = i*segment_length                          # (jototomo tukra * tukrar length) theke start. like 0*3=0 or 1*3=3       \n",
    "        end = min((i+1)*segment_length, len(p))           # (i+1)*segment_len hobe end point\n",
    "        p_bm = BoyerMoore(p[start:end], alphabet='ACGT')  # preprocess korte pathate hbe\n",
    "        matches = boyer_moore(p[start:end], p_bm, t)      # koyta match holo tader offset index dibe\n",
    "        \n",
    "        for m in matches:                                 # proti ta match e jabo (segment match index)\n",
    "            if m < start or m-start+len(p) > len(t):      # seg jekhane start hoise, tar age toh match howa possible na, ar match koranor somoy len(t) exceed kora jabena\n",
    "                continue\n",
    "                \n",
    "            mismatches = 0\n",
    "            for j in range(0, start):                     # segment ta p er jekhan theke start hoise tar ag porjonto p==t hoise kina check\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            \n",
    "            for j in range(end, len(p)):                  # segment jekhane ses hoise tar por theke p er ses porjonto p==t kina check\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            \n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m-start)   \n",
    "    return list(all_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_2mm(p, t):\n",
    "    occurances = []\n",
    "    for i in range(len(t)-len(p)+1):\n",
    "        match = True\n",
    "        cnt=0\n",
    "        for j in range(len(p)):\n",
    "            if t[i+j] != p[j]:\n",
    "                cnt+=1\n",
    "        if cnt>2:\n",
    "            match = False\n",
    "        if match == True:\n",
    "            occurances.append(i)\n",
    "    return occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "class Index(object):\n",
    "    def __init__(self, t, k):\n",
    "        self.k = k                                      # k-mer length = k\n",
    "        self.index = []   \n",
    "        for i in range(len(t) - k + 1):\n",
    "            self.index.append((t[i:i+k], i))            # kmer gula bosano hoise (string, index) touple diye\n",
    "        self.index.sort()\n",
    "        \n",
    "    def query(self, p):\n",
    "        for j in range(len(p)-self.k+1):\n",
    "            kmer = p[:self.k]                                # given str p theke k ta char nite hbe kmer hisabe\n",
    "            i = bisect.bisect_left(self.index, (kmer, -1))   # i = kmer kon index e boste parbe seta find korbe (syxtax e amon), right the left e khujbe and leftmost index return krbe\n",
    "            hits = []\n",
    "            while i < len(self.index):\n",
    "                c = 0\n",
    "                for pp in range(len(kmer)):\n",
    "                    if self.index[i][0][pp] != kmer[pp]:\n",
    "                        c+=1\n",
    "                if c>2:\n",
    "                    break\n",
    "                #if len(approximate_match(self.index[i][0], p, 2))==0:\n",
    "                    #break\n",
    "                hits.append(self.index[i][1])                # i jodi kmer hoy tahole sei kmer er index collect kora hbe\n",
    "                i += 1                                       # i leftmost index return krbe, tai i++ kore dekhte hbe aro hit ache kina\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = genome\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922, 57056, 83720, 84641, 147558, 160729, 191452, 262042, 364263, 657496, 681737, 717706, 725061, 83871]\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "True\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGGCAGGCGCCTGTAGT\n",
      "False\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGATTCATGCCTGTAAT\n",
      "False\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGGCTCATGCCTGTAAT\n",
      "False\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGGCTCATGCCTGTAAT\n",
      "False\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGGCTCACACCTGTAAT\n",
      "False\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGGTTCACGCCTGTAAT\n",
      "False\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "True\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "True\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "True\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGGCTCATGCCTGTAAT\n",
      "False\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "True\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGGTGGCAGGCGCCTGTAGT\n",
      "False\n",
      "p =  GGCGCGGTGGCTCACGCCTGTAAT\n",
      "s =  GGCGCGTGCCTGTAATCCCAGCTA\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "index = Index(t, 8)              # t str diye 8-mer set hbe\n",
    "print(index.query(p))  # query diye only k-mer search kore, queryIndex diye full p search kore\n",
    "#'''print(p)\n",
    "for i in index.query(p):\n",
    "    print('p = ', p)\n",
    "    print('s = ', genome[i:i+24])\n",
    "    print(p==genome[i:i+24])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryIndex(p, t, index):\n",
    "    k = index.k                       # index = Index class er obj. so k = joto k set kora hoise\n",
    "    offsets = []                      # kothay kothay full p str match korse\n",
    "    for i in index.query(p):  \n",
    "        if p[k:] == t[i+k:i+len(p)]:  # p[k:] karon first k ta k-mer diyei hoye gese. tai k theke len(p) porjonto check krte hbe   \n",
    "            offsets.append(i) \n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922, 262042, 364263, 657496, 717706, 551134, 273669]\n"
     ]
    }
   ],
   "source": [
    "print(queryIndex(p, t, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GGCGCGTGCCTGTAATCCCAGCTA'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome[83871:83871+24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "   \n",
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "    \n",
    "    def __init__(self, t, k, ival):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.span = 1 + ival * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i+self.span:ival], i))  # add (subseq, offset)\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "    \n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            #if self.index[i][0] != subseq:\n",
    "            nv = naive_2mm(self.index[i][0], subseq)\n",
    "            if len(nv)==0:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AAA', 0), ('TTT', 1)]\n"
     ]
    }
   ],
   "source": [
    "ind = SubseqIndex('ATATAT', 3, 2)\n",
    "print(ind.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "p = 'TTATAT'\n",
    "print(ind.query(p[0:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(ind.query(p[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "t = genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = SubseqIndex(genome, 8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TTGAATGCTGAAATCAGCAGGTAATATATGATAATAGAGAAAGCTATCCCGAAGGTGCATAGGTCAACAATACTTGAGCCTAACTCAGTAGATCCTAAAA'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AAAAAAAA', 1879), ('AAAAAAAA', 1882), ('AAAAAAAA', 1885), ('AAAAAAAA', 1888), ('AAAAAAAA', 2989), ('AAAAAAAA', 2992), ('AAAAAAAA', 2995), ('AAAAAAAA', 2996), ('AAAAAAAA', 2998), ('AAAAAAAA', 2999), ('AAAAAAAA', 3774), ('AAAAAAAA', 6370), ('AAAAAAAA', 7241), ('AAAAAAAA', 33796), ('AAAAAAAA', 33828), ('AAAAAAAA', 33831), ('AAAAAAAA', 35720), ('AAAAAAAA', 37621), ('AAAAAAAA', 38271), ('AAAAAAAA', 38910), ('AAAAAAAA', 38913), ('AAAAAAAA', 43081), ('AAAAAAAA', 43084), ('AAAAAAAA', 43087), ('AAAAAAAA', 43090), ('AAAAAAAA', 46338), ('AAAAAAAA', 46341), ('AAAAAAAA', 54148), ('AAAAAAAA', 54151), ('AAAAAAAA', 54154), ('AAAAAAAA', 54157), ('AAAAAAAA', 57205), ('AAAAAAAA', 57206), ('AAAAAAAA', 57207), ('AAAAAAAA', 57208), ('AAAAAAAA', 57209), ('AAAAAAAA', 57210), ('AAAAAAAA', 57211), ('AAAAAAAA', 57212), ('AAAAAAAA', 59231), ('AAAAAAAA', 59234), ('AAAAAAAA', 59237), ('AAAAAAAA', 59240), ('AAAAAAAA', 59243), ('AAAAAAAA', 60945), ('AAAAAAAA', 65524), ('AAAAAAAA', 69483), ('AAAAAAAA', 69486), ('AAAAAAAA', 69520), ('AAAAAAAA', 72452), ('AAAAAAAA', 72455), ('AAAAAAAA', 72458), ('AAAAAAAA', 72461), ('AAAAAAAA', 73172), ('AAAAAAAA', 83837), ('AAAAAAAA', 84919), ('AAAAAAAA', 84922), ('AAAAAAAA', 84925), ('AAAAAAAA', 84928), ('AAAAAAAA', 88791), ('AAAAAAAA', 88794), ('AAAAAAAA', 88797), ('AAAAAAAA', 88800), ('AAAAAAAA', 105432), ('AAAAAAAA', 105435), ('AAAAAAAA', 105438), ('AAAAAAAA', 109575), ('AAAAAAAA', 109576), ('AAAAAAAA', 109578), ('AAAAAAAA', 113311), ('AAAAAAAA', 114295), ('AAAAAAAA', 114298), ('AAAAAAAA', 114301), ('AAAAAAAA', 115966), ('AAAAAAAA', 121369), ('AAAAAAAA', 121372), ('AAAAAAAA', 124173), ('AAAAAAAA', 124176), ('AAAAAAAA', 124177), ('AAAAAAAA', 124179), ('AAAAAAAA', 124180), ('AAAAAAAA', 124182), ('AAAAAAAA', 124185), ('AAAAAAAA', 124188), ('AAAAAAAA', 125351), ('AAAAAAAA', 125354), ('AAAAAAAA', 125357), ('AAAAAAAA', 127208), ('AAAAAAAA', 133591), ('AAAAAAAA', 135083), ('AAAAAAAA', 135086), ('AAAAAAAA', 135089), ('AAAAAAAA', 137783), ('AAAAAAAA', 137786), ('AAAAAAAA', 141593), ('AAAAAAAA', 141596), ('AAAAAAAA', 141599), ('AAAAAAAA', 141602), ('AAAAAAAA', 141605), ('AAAAAAAA', 141608)]\n"
     ]
    }
   ],
   "source": [
    "print(ind.index[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922, 67486, 83863, 84641, 84775, 124024, 147558, 191452, 199607, 262042, 262174, 273669, 322735, 364263, 421354, 454332, 465647, 471966, 472634, 489019, 558456, 579737, 596898, 635931, 651523, 657496, 658702, 681737, 707151, 712449, 717706, 719418, 719557, 746620, 747359, 171452, 251261, 261099, 278079, 292141, 442303, 460493, 499922, 613117, 775976, 215147, 222432, 441721, 511100]\n"
     ]
    }
   ],
   "source": [
    "print(ind.query(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print(len(ind.query(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print(len(ind.query(p[0:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ind.query(p[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ind.query(p[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ind.query(p[3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ind.query(p[4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ind.query(p[7:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
